{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T12:52:30.747354Z",
     "iopub.status.busy": "2025-08-24T12:52:30.746795Z",
     "iopub.status.idle": "2025-08-24T13:03:15.932056Z",
     "shell.execute_reply": "2025-08-24T13:03:15.931426Z",
     "shell.execute_reply.started": "2025-08-24T12:52:30.747327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 829 images belonging to 2 classes.\n",
      "Found 506 images belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4922 - loss: 1.0425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siri Priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "c:\\Users\\Siri Priya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.51267, saving model to /kaggle/working/fracture_model_best.keras\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m813s\u001b[0m 6s/step - accuracy: 0.5056 - loss: 0.9988 - val_accuracy: 0.5127 - val_loss: 0.7659 - learning_rate: 1.0000e-04\n",
      "Epoch 2/7\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5398 - loss: 0.8950\n",
      "Epoch 2: val_accuracy improved from 0.51267 to 0.62485, saving model to /kaggle/working/fracture_model_best.keras\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m779s\u001b[0m 5s/step - accuracy: 0.5527 - loss: 0.8614 - val_accuracy: 0.6248 - val_loss: 0.6570 - learning_rate: 1.0000e-04\n",
      "Epoch 3/7\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6026 - loss: 0.7757\n",
      "Epoch 3: val_accuracy improved from 0.62485 to 0.70205, saving model to /kaggle/working/fracture_model_best.keras\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m795s\u001b[0m 5s/step - accuracy: 0.5972 - loss: 0.7767 - val_accuracy: 0.7021 - val_loss: 0.5912 - learning_rate: 1.0000e-04\n",
      "Epoch 4/7\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6243 - loss: 0.7158\n",
      "Epoch 4: val_accuracy improved from 0.70205 to 0.73583, saving model to /kaggle/working/fracture_model_best.keras\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m951s\u001b[0m 7s/step - accuracy: 0.6291 - loss: 0.7025 - val_accuracy: 0.7358 - val_loss: 0.5485 - learning_rate: 1.0000e-04\n",
      "Epoch 5/7\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.6621 - loss: 0.6584\n",
      "Epoch 5: val_accuracy improved from 0.73583 to 0.77684, saving model to /kaggle/working/fracture_model_best.keras\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1462s\u001b[0m 10s/step - accuracy: 0.6645 - loss: 0.6521 - val_accuracy: 0.7768 - val_loss: 0.5093 - learning_rate: 1.0000e-04\n",
      "Epoch 6/7\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6842 - loss: 0.6179\n",
      "Epoch 6: val_accuracy improved from 0.77684 to 0.79493, saving model to /kaggle/working/fracture_model_best.keras\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m876s\u001b[0m 6s/step - accuracy: 0.6959 - loss: 0.6014 - val_accuracy: 0.7949 - val_loss: 0.4864 - learning_rate: 1.0000e-04\n",
      "Epoch 7/7\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6962 - loss: 0.6141\n",
      "Epoch 7: val_accuracy improved from 0.79493 to 0.80579, saving model to /kaggle/working/fracture_model_best.keras\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 6s/step - accuracy: 0.7014 - loss: 0.5977 - val_accuracy: 0.8058 - val_loss: 0.4693 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Final model saved as fracture_20250829_174841.keras\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6s/step - accuracy: 0.7194 - loss: 0.5642\n",
      "\n",
      "Final Test Accuracy: 0.7194, Test Loss: 0.5642\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Fix truncated images\n",
    "# --------------------------\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# --------------------------\n",
    "# Imports\n",
    "# --------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# --------------------------\n",
    "# Mixed precision\n",
    "# --------------------------\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# --------------------------\n",
    "# Paths\n",
    "# --------------------------\n",
    "train_dir = r\"E:\\Engineering\\5 th sem\\Project Sem 5\\HPC\\Dataset\\Bone_Fracture_Binary_Classification\\Bone_Fracture_Binary_Classification\\train\"\n",
    "val_dir   = r\"E:\\Engineering\\5 th sem\\Project Sem 5\\HPC\\Dataset\\Bone_Fracture_Binary_Classification\\Bone_Fracture_Binary_Classification\\val\"\n",
    "test_dir  = r\"E:\\Engineering\\5 th sem\\Project Sem 5\\HPC\\Dataset\\Bone_Fracture_Binary_Classification\\Bone_Fracture_Binary_Classification\\test\"\n",
    "\n",
    "# --------------------------\n",
    "# Parameters\n",
    "# --------------------------\n",
    "classes = [\"fractured\", \"not fractured\"]  # EXACT folder names\n",
    "img_size = (160, 160)\n",
    "batch_size = 64\n",
    "\n",
    "# --------------------------\n",
    "# Prepare true balanced training generator\n",
    "# --------------------------\n",
    "file_paths = {cls: [os.path.join(train_dir, cls, f) for f in os.listdir(os.path.join(train_dir, cls))] for cls in classes}\n",
    "max_count = max(len(file_paths[cls]) for cls in classes)\n",
    "\n",
    "# Oversample minority class\n",
    "for cls in classes:\n",
    "    n = len(file_paths[cls])\n",
    "    if n < max_count:\n",
    "        extra = np.random.choice(file_paths[cls], max_count - n, replace=True)\n",
    "        file_paths[cls].extend(extra)\n",
    "\n",
    "# Flatten and shuffle\n",
    "all_files = []\n",
    "all_labels = []\n",
    "for i, cls in enumerate(classes):\n",
    "    all_files.extend(file_paths[cls])\n",
    "    all_labels.extend([i] * len(file_paths[cls]))\n",
    "all_files, all_labels = shuffle(all_files, all_labels, random_state=42)\n",
    "\n",
    "# Generator\n",
    "def balanced_generator(file_paths, labels, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(file_paths), batch_size):\n",
    "            batch_files = file_paths[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            batch_images = []\n",
    "            for f in batch_files:\n",
    "                img = tf.keras.preprocessing.image.load_img(f, target_size=img_size)\n",
    "                x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                x = preprocess_input(x)\n",
    "                batch_images.append(x)\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "train_gen = balanced_generator(all_files, all_labels, batch_size)\n",
    "steps_per_epoch = len(all_files) // batch_size\n",
    "\n",
    "# --------------------------\n",
    "# Validation & test generators\n",
    "# --------------------------\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_gen = val_datagen.flow_from_directory(val_dir, target_size=img_size, batch_size=batch_size, class_mode='binary')\n",
    "test_gen = val_datagen.flow_from_directory(test_dir, target_size=img_size, batch_size=batch_size, class_mode='binary', shuffle=False)\n",
    "\n",
    "# --------------------------\n",
    "# DenseNet121 model\n",
    "# --------------------------\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=img_size+(3,))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(1, activation='sigmoid', dtype='float32')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Callbacks\n",
    "# --------------------------\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='/kaggle/working/fracture_model_best.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# --------------------------\n",
    "# Train Phase 1: Frozen base\n",
    "# --------------------------\n",
    "history1 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=7,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Fine-tune last 50 layers\n",
    "# --------------------------\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=optimizers.Adam(1e-5),\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# history2 = model.fit(\n",
    "#     train_gen,\n",
    "#     validation_data=val_gen,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     validation_steps=len(val_gen),\n",
    "#     epochs=10,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# --------------------------\n",
    "# Save final model with timestamp\n",
    "# --------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_model_name = f\"fracture_{timestamp}.keras\"\n",
    "model.save(final_model_name)\n",
    "print(f\"Final model saved as {final_model_name}\")\n",
    "\n",
    "# --------------------------\n",
    "# Evaluate on test set\n",
    "# --------------------------\n",
    "loss, acc = model.evaluate(test_gen)\n",
    "print(f\"\\nFinal Test Accuracy: {acc:.4f}, Test Loss: {loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4854718,
     "sourceId": 8201044,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
